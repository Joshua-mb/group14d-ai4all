{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Tweets Sentiment Analysis with VADER\n",
    "\n",
    "This notebook performs sentiment analysis on stock-related tweets using VADER (Valence Aware Dictionary and sEntiment Reasoner).\n",
    "\n",
    "**VADER** is specifically designed for social media text and works well with:\n",
    "- Emojis\n",
    "- Slang\n",
    "- Abbreviations\n",
    "- Capitalization (for emphasis)\n",
    "\n",
    "**Sentiment Scores:**\n",
    "- `positive`: Positive sentiment score (0-1)\n",
    "- `negative`: Negative sentiment score (0-1)\n",
    "- `neutral`: Neutral sentiment score (0-1)\n",
    "- `compound`: Overall sentiment (-1 to +1)\n",
    "  - **compound >= 0.05**: Positive\n",
    "  - **compound <= -0.05**: Negative\n",
    "  - **-0.05 < compound < 0.05**: Neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned stock tweets data\n",
    "df = pd.read_csv('Cleaned_Stock_Tweets.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nTotal Tweets: {len(df):,}\")\n",
    "print(f\"Unique Stocks: {df['Stock Name'].nunique()}\")\n",
    "print(f\"\\nTop 5 Stocks by Tweet Count:\")\n",
    "print(df['Stock Name'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize VADER Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test VADER on a sample tweet\n",
    "sample_tweet = df['Tweet'].iloc[0]\n",
    "sample_scores = analyzer.polarity_scores(sample_tweet)\n",
    "\n",
    "print(\"Sample Tweet:\")\n",
    "print(f\"{sample_tweet}\\n\")\n",
    "print(\"Sample Sentiment Scores:\")\n",
    "print(sample_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply Sentiment Analysis to All Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment scores\n",
    "def get_sentiment_scores(text):\n",
    "    \"\"\"\n",
    "    Analyzes sentiment of text using VADER.\n",
    "    Returns a dictionary with sentiment scores.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0}\n",
    "    return analyzer.polarity_scores(str(text))\n",
    "\n",
    "# Apply sentiment analysis (this may take a minute)\n",
    "print(\"Analyzing sentiment for all tweets...\")\n",
    "print(\"This may take a minute depending on dataset size...\\n\")\n",
    "\n",
    "# Get sentiment scores for each tweet\n",
    "sentiment_scores = df['Tweet'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each score\n",
    "df['sentiment_negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "df['sentiment_neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "df['sentiment_positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "df['sentiment_compound'] = sentiment_scores.apply(lambda x: x['compound'])\n",
    "\n",
    "print(\"âœ… Sentiment analysis complete!\")\n",
    "print(f\"\\nProcessed {len(df):,} tweets\")\n",
    "\n",
    "# Display sample results\n",
    "df[['Tweet', 'sentiment_negative', 'sentiment_neutral', 'sentiment_positive', 'sentiment_compound']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Classify Sentiment as Positive/Negative/Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify sentiment based on compound score\n",
    "def classify_sentiment(compound_score):\n",
    "    \"\"\"\n",
    "    Classifies sentiment based on compound score:\n",
    "    - Positive: compound >= 0.05\n",
    "    - Negative: compound <= -0.05\n",
    "    - Neutral: -0.05 < compound < 0.05\n",
    "    \"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply classification\n",
    "df['sentiment_label'] = df['sentiment_compound'].apply(classify_sentiment)\n",
    "\n",
    "# Display distribution\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['sentiment_label'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Overall Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart of sentiment distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c', '#95a5a6']  # Green, Red, Gray\n",
    "ax1.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax1.set_title('Overall Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "sentiment_counts.plot(kind='bar', ax=ax2, color=colors)\n",
    "ax2.set_title('Sentiment Counts', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Sentiment', fontsize=12)\n",
    "ax2.set_ylabel('Number of Tweets', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Sentiment by Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment by stock\n",
    "stock_sentiment = df.groupby('Stock Name').agg({\n",
    "    'sentiment_compound': 'mean',\n",
    "    'Tweet': 'count'\n",
    "}).rename(columns={'Tweet': 'tweet_count'})\n",
    "\n",
    "stock_sentiment = stock_sentiment.sort_values('sentiment_compound', ascending=False)\n",
    "\n",
    "print(\"Average Sentiment by Stock (Top 10):\")\n",
    "print(stock_sentiment.head(10))\n",
    "print(\"\\nBottom 10:\")\n",
    "print(stock_sentiment.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 stocks by average sentiment\n",
    "top_10_stocks = stock_sentiment.head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors_map = ['#2ecc71' if x >= 0 else '#e74c3c' for x in top_10_stocks['sentiment_compound']]\n",
    "plt.barh(top_10_stocks.index, top_10_stocks['sentiment_compound'], color=colors_map)\n",
    "plt.xlabel('Average Sentiment (Compound Score)', fontsize=12)\n",
    "plt.ylabel('Stock', fontsize=12)\n",
    "plt.title('Top 10 Stocks by Average Sentiment', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Sentiment Distribution by Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentiment distribution for top stocks (by tweet count)\n",
    "top_stocks = df['Stock Name'].value_counts().head(5).index\n",
    "\n",
    "# Create a stacked bar chart\n",
    "sentiment_by_stock = pd.crosstab(df[df['Stock Name'].isin(top_stocks)]['Stock Name'], \n",
    "                                  df[df['Stock Name'].isin(top_stocks)]['sentiment_label'],\n",
    "                                  normalize='index') * 100\n",
    "\n",
    "sentiment_by_stock[['Positive', 'Neutral', 'Negative']].plot(kind='bar', \n",
    "                                                               stacked=True,\n",
    "                                                               color=['#2ecc71', '#95a5a6', '#e74c3c'],\n",
    "                                                               figsize=(12, 6))\n",
    "plt.title('Sentiment Distribution for Top 5 Stocks (by Tweet Count)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Stock', fontsize=12)\n",
    "plt.ylabel('Percentage (%)', fontsize=12)\n",
    "plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Analyze Sentiment Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Calculate daily average sentiment\n",
    "daily_sentiment = df.groupby(df['Date'].dt.date)['sentiment_compound'].mean()\n",
    "\n",
    "# Plot sentiment over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment.values, linewidth=2, color='#3498db')\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "plt.fill_between(daily_sentiment.index, daily_sentiment.values, 0, \n",
    "                 where=(daily_sentiment.values >= 0), alpha=0.3, color='#2ecc71', label='Positive')\n",
    "plt.fill_between(daily_sentiment.index, daily_sentiment.values, 0, \n",
    "                 where=(daily_sentiment.values < 0), alpha=0.3, color='#e74c3c', label='Negative')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Average Sentiment (Compound Score)', fontsize=12)\n",
    "plt.title('Average Sentiment Over Time', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Most Positive and Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most positive tweets\n",
    "print(\"ðŸŸ¢ TOP 5 MOST POSITIVE TWEETS:\")\n",
    "print(\"=\" * 80)\n",
    "most_positive = df.nlargest(5, 'sentiment_compound')[['Tweet', 'Stock Name', 'sentiment_compound']]\n",
    "for idx, row in most_positive.iterrows():\n",
    "    print(f\"\\nStock: {row['Stock Name']} | Score: {row['sentiment_compound']:.3f}\")\n",
    "    print(f\"Tweet: {row['Tweet'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most negative tweets\n",
    "print(\"ðŸ”´ TOP 5 MOST NEGATIVE TWEETS:\")\n",
    "print(\"=\" * 80)\n",
    "most_negative = df.nsmallest(5, 'sentiment_compound')[['Tweet', 'Stock Name', 'sentiment_compound']]\n",
    "for idx, row in most_negative.iterrows():\n",
    "    print(f\"\\nStock: {row['Stock Name']} | Score: {row['sentiment_compound']:.3f}\")\n",
    "    print(f\"Tweet: {row['Tweet'][:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "print(\"ðŸ“Š SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal Tweets Analyzed: {len(df):,}\")\n",
    "print(f\"Date Range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "print(f\"Number of Unique Stocks: {df['Stock Name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Overall Sentiment Statistics:\")\n",
    "print(f\"  Average Compound Score: {df['sentiment_compound'].mean():.3f}\")\n",
    "print(f\"  Median Compound Score: {df['sentiment_compound'].median():.3f}\")\n",
    "print(f\"  Std Deviation: {df['sentiment_compound'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Sentiment Breakdown:\")\n",
    "sentiment_pct = df['sentiment_label'].value_counts(normalize=True) * 100\n",
    "for label, pct in sentiment_pct.items():\n",
    "    print(f\"  {label}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nâ­ Most Discussed Stocks:\")\n",
    "top_3_stocks = df['Stock Name'].value_counts().head(3)\n",
    "for stock, count in top_3_stocks.items():\n",
    "    avg_sentiment = df[df['Stock Name'] == stock]['sentiment_compound'].mean()\n",
    "    print(f\"  {stock}: {count:,} tweets | Avg Sentiment: {avg_sentiment:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe with sentiment scores to a new CSV file\n",
    "output_filename = 'Stock_Tweets_With_Sentiment.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Results saved to: {output_filename}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(\"  - sentiment_negative\")\n",
    "print(\"  - sentiment_neutral\")\n",
    "print(\"  - sentiment_positive\")\n",
    "print(\"  - sentiment_compound\")\n",
    "print(\"  - sentiment_label (Positive/Negative/Neutral)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report by stock\n",
    "summary_report = df.groupby('Stock Name').agg({\n",
    "    'Tweet': 'count',\n",
    "    'sentiment_compound': ['mean', 'std', 'min', 'max'],\n",
    "    'sentiment_positive': 'mean',\n",
    "    'sentiment_negative': 'mean',\n",
    "    'sentiment_neutral': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "# Flatten column names\n",
    "summary_report.columns = ['_'.join(col).strip() for col in summary_report.columns.values]\n",
    "summary_report = summary_report.rename(columns={'Tweet_count': 'tweet_count'})\n",
    "\n",
    "# Add sentiment label counts\n",
    "sentiment_counts = df.groupby(['Stock Name', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "summary_report = summary_report.join(sentiment_counts)\n",
    "\n",
    "# Sort by tweet count\n",
    "summary_report = summary_report.sort_values('tweet_count', ascending=False)\n",
    "\n",
    "# Save summary report\n",
    "summary_filename = 'Sentiment_Summary_By_Stock.csv'\n",
    "summary_report.to_csv(summary_filename)\n",
    "\n",
    "print(f\"âœ… Summary report saved to: {summary_filename}\")\n",
    "print(f\"\\nPreview of summary report:\")\n",
    "summary_report.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Analysis Complete!\n",
    "\n",
    "### What You've Done:\n",
    "1. âœ… Loaded and explored your stock tweets dataset\n",
    "2. âœ… Applied VADER sentiment analysis to all tweets\n",
    "3. âœ… Created visualizations of sentiment distributions\n",
    "4. âœ… Analyzed sentiment by stock and over time\n",
    "5. âœ… Identified most positive and negative tweets\n",
    "6. âœ… Saved results to CSV files\n",
    "\n",
    "### Output Files:\n",
    "- `Stock_Tweets_With_Sentiment.csv` - Full dataset with sentiment scores\n",
    "- `Sentiment_Summary_By_Stock.csv` - Summary statistics by stock\n",
    "\n",
    "### Next Steps (Optional):\n",
    "- Compare sentiment with actual stock price movements\n",
    "- Analyze correlation between tweet volume and sentiment\n",
    "- Build a sentiment trend predictor\n",
    "- Filter by specific date ranges or stocks for deeper analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
